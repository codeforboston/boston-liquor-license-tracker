{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96aa3417",
   "metadata": {},
   "source": [
    "# Not Used!!\n",
    "\n",
    "- Exploring options for address normalization.\n",
    "- But abandoned because of poor results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ccc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "json_dir = \"../data/license_json\"\n",
    "source_dir = Path(\"../data/license_text\")\n",
    "target_dir = Path(\"../data/license_text_fix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70168f",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Read all `.json` files from the `license_json` directory and combine them into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "if os.path.exists(json_dir):\n",
    "    files = [f for f in os.listdir(json_dir) if f.endswith(\".json\")]\n",
    "    print(f\"Found {len(files)} JSON files.\")\n",
    "\n",
    "    for filename in files:\n",
    "        with open(os.path.join(json_dir, filename)) as f:\n",
    "            try:\n",
    "                record = json.load(f)\n",
    "                data.append(record)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "else:\n",
    "    print(f\"Error: {json_dir} directory not found.\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"DataFrame created with {len(df)} rows and {len(df.columns)} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def call_nominatim(call_type, params):\n",
    "    \"\"\"\n",
    "    Fetches a address related to this code\n",
    "    \"\"\"\n",
    "    NOMINATIM_URL = \"http://127.0.0.1:8080\"\n",
    "\n",
    "    url = f\"{NOMINATIM_URL}/{call_type}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors (4xx or 5xx)\n",
    "        route_data = response.json()\n",
    "        return route_data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching route: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def geocode(query):\n",
    "    try:\n",
    "        params = {\"q\": query, \"format\": \"json\", \"limit\": 1}\n",
    "\n",
    "        response = call_nominatim(\"search\", params)\n",
    "\n",
    "        # Expecting a list of dicts\n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            first = response[0]\n",
    "\n",
    "            lat = first.get(\"lat\")\n",
    "            lon = first.get(\"lon\")\n",
    "\n",
    "            # Ensure both values exist\n",
    "            if lat is not None and lon is not None:\n",
    "                return (float(lat), float(lon))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Geocoding failed for '{query}': {e}\")\n",
    "\n",
    "    return (None, None)\n",
    "\n",
    "\n",
    "def reverse_geocode(lat, lon):\n",
    "    response = (None, None, None)\n",
    "    try:\n",
    "        params = {\"lat\": lat, \"lon\": lon, \"format\": \"json\", \"addressdetails\": 1}\n",
    "\n",
    "        response = call_nominatim(\"reverse\", params)\n",
    "\n",
    "        # Expecting a list of dicts\n",
    "        if isinstance(response, dict):\n",
    "            addr_str = None\n",
    "            addresstype = response.get(\"addresstype\", None)\n",
    "            address = response.get(\"address\", None)\n",
    "            if address:\n",
    "                house_number = address.get(\"house_number\", \"\")\n",
    "                road = address.get(\"road\", \"\")\n",
    "                town = address.get(\"town\", \"\")\n",
    "                state = address.get(\"state\", \"\")\n",
    "                postcode = address.get(\"postcode\", \"\")\n",
    "                amenity = address.get(\"amenity\", \"\")\n",
    "                addr_str = f\"{house_number} {road}, {town}\"\n",
    "            return (addr_str, addresstype, amenity)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Reverse Geocoding failed for '[{lat},{lon}]': {e}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_licenses = df[\"license_number\"].unique()\n",
    "unique_licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"minutes_date\"] = pd.to_datetime(df[\"minutes_date\"], errors=\"coerce\")\n",
    "\n",
    "df_sorted = df.sort_values(by=\"minutes_date\", ascending=False)\n",
    "df_unique_newest = df_sorted.drop_duplicates(\"license_number\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "df_geo = df_unique_newest.copy()\n",
    "cols_to_drop = [\n",
    "    \"minutes_date\",\n",
    "    \"business_name\",\n",
    "    \"dba_name\",\n",
    "    \"alcohol_type\",\n",
    "    \"manager\",\n",
    "    \"attorney\",\n",
    "    \"status\",\n",
    "    \"status_detail\",\n",
    "    \"hours\",\n",
    "    \"details\",\n",
    "    \"entity_number\",\n",
    "    \"file_name\",\n",
    "]\n",
    "df_geo = df_geo.drop(columns=cols_to_drop)\n",
    "df_geo\n",
    "# Limit to first 5 rows\n",
    "# df_geo = df_geo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Add empty columns\n",
    "df_geo[[\"lat\", \"lon\", \"house_number\", \"road\", \"town\", \"state\", \"postcode\"]] = None\n",
    "\n",
    "for idx, row in df_geo.iterrows():\n",
    "    address = row[\"address\"]\n",
    "\n",
    "    # --- Forward geocode ---\n",
    "    lat, lon = geocode(address)\n",
    "\n",
    "    df_geo.at[idx, \"lat\"] = lat\n",
    "    df_geo.at[idx, \"lon\"] = lon\n",
    "\n",
    "    # --- Reverse geocode if we got valid coords ---\n",
    "    if lat is not None and lon is not None:\n",
    "        addr_str, addresstype, amenity = reverse_geocode(lat, lon)\n",
    "\n",
    "        # Your reverse_geocode returns a string and some metadata,\n",
    "        # but we want structured fields, so call again properly:\n",
    "        response = call_nominatim(\n",
    "            \"reverse\", {\"lat\": lat, \"lon\": lon, \"format\": \"json\", \"addressdetails\": 1}\n",
    "        )\n",
    "\n",
    "        if isinstance(response, dict):\n",
    "            address_details = response.get(\"address\", {})\n",
    "\n",
    "            df_geo.at[idx, \"house_number\"] = address_details.get(\"house_number\")\n",
    "            df_geo.at[idx, \"road\"] = address_details.get(\"road\")\n",
    "            df_geo.at[idx, \"town\"] = (\n",
    "                address_details.get(\"town\")\n",
    "                or address_details.get(\"city\")\n",
    "                or address_details.get(\"village\")\n",
    "            )\n",
    "            df_geo.at[idx, \"state\"] = address_details.get(\"state\")\n",
    "            df_geo.at[idx, \"postcode\"] = address_details.get(\"postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Ensure columns are strings and saved with quotes\n",
    "df_geo[\"zipcode\"] = df_geo[\"zipcode\"].astype(str)\n",
    "df_geo[\"postcode\"] = df_geo[\"postcode\"].astype(str)\n",
    "\n",
    "df_geo.to_csv(\"address_test.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76be91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
